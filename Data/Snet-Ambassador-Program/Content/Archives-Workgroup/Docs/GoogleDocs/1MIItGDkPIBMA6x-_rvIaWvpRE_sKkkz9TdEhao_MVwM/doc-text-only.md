# AI Ethics Strategy for sNET Archives



# Overview

## Consent



Respect for Beings, Sentient and non Sentient persons

Open Source and Creative Commons licensing

GDPR



## Beneficial

Do no harm

Benefits all of humanity, not just segments or groups





## Justice



Considerations of equity and equality

Considerations of need and effort

Recognising individual effort and contribution

Recognising merit



## Human-centredness?

AI systems should be designed to augment and support human decision-making, not replace it. The SingularityNET Archives will promote human-AI collaboration ,  and will ensure that humans re main in the Loop for guidance and have final say tain  control over AI systems and their outputs when necessary. .





# AI Risks



## 1. Hallucinations (lies   lol)

Factual errors presented as semantic truths



LLMs do not understand meaning they only return semantic indices (still can be lies  lol)



### Mitigation



Explainability - link to the Why of the response and provide sources (is this also transparency?)

## 2. Bias



Bias in how sources are structured, retrieved, augmented and generated (presented).



### Mitigation



Culture awareness and auditing



Broad prompts may reproduce bias in a sample

Be aware that your question may reflect your culture

Audit responses to see how your data reflects your culture



## 3. Consent

Attribution and copyright issues



### Mitigation



Auditing - check provenance of sources

Accountability Accountivity - check ownership and l i cen s c ing



## 4. Security



Abuse of data - manipulation of private information



Jailbreaking

Prompt injection - malicious prompt manipulation



### Mitigation



Education



Does data augmentation empower the user ?







# Culture



What is your culture ?



What is the intent of your use of AI ?



Your Ethos ?



Is it a consent based process ?



# Governance



Roles and responsibilities of people working with AI

Education about benevolent AI lifecycles

AI risk management and mitigation

How to ensure trust and accountability  ? I think all human-ai-interaction should be recorded, thus keeping it Decentralized



We need to consider the scope of the SNet Archive. A broadly based large generative model is often called a Foundation model. But our intent may be to start with narrowly based data sources that are simply augmented with generative tools. In short we may want to start with just being able to ask the Archive simple questions. But even this step will reveal bias and culture. We need to observe what questions get asked and ask why. Only then can we meaningfully audit the results.







# Sources



## IBM AI Ethics





https://www.ibm.com/impact/ai-ethics

https://www.ibm.com/topics/ai-ethics



## AI Fairness 360

This extensible open source toolkit can help you examine, report, and mitigate discrimination and bias in machine learning models throughout the AI application lifecycle. We invite you to use and improve it.

https://aif360.res.ibm.com/

## Oxford Institute for Ethics in AI

https://www.oxford-aiethics.ox.ac.uk/



