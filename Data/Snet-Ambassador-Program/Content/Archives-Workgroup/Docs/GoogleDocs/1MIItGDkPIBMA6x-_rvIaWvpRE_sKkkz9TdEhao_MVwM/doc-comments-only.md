#### Context - outputs
> * Colleen Pridemore: ...until such a time where consciousness begins to emerge in the AI then we will have to switch to "Guiding" AI.
> 
#### Context - Culture

What is your culture ?

What is the intent of your use of AI ? 

Your Ethos ?

Is it a consent based process ?
> * Jenni Illona Mayshiogie: I hope for intense discussions about this discourse ðŸ™
>   - Colleen Pridemore: ME too Jenni.Â  I believe the intent of our use of AI, like the ChatGPTÂ  AI Ethics Snet Ambassadors we will use for education both internally and with the rest of the community and ultimately, with the world.
> 
#### Context - AI
> * Martin Soki35: My approach ensures that AI systems support rather than replace human decision-making, aligning with contemporary ethical standards. Additionally, I address AI risks such as hallucinations, bias, and security issues, with mitigations through explainability, cultural awareness, and education. This proactive stance will foster trustworthy and accountable AI systems, contributing to ethical, fair, and beneficial outcomes for all stakeholders.
> 
#### Context - Attribution and copyright issues
> * Vanessa Cardui: I think "consent" might cover more than just attribution and copyright.

Is there something here about consent to AI being used at all in a service? Like, a "right to refuse"? Should people be able to say, for example, "I don't want to be assessed by AI for a bank loan" or "I don't want my doctor to use AI to diagnose me" or "I want access to a non-AI search tool on this website" or whatever? Obvs could be hugely impractical - but do/should people have that right? or maybe, should they have it in some contexts?
This prolly connects with the idea of transparency - **knowing** when AI is being used and when it's not - but it occurs to me that transparency is a bit toothless if poeple cannot also object/refuse.
> 
#### Context - Hallucinations
> * Colleen Pridemore: I heard MeTTa is working on LLM Hallucinations?
> 
#### Context - Recognising merit
> * Vanessa Cardui: who defines "merit"? and how is the definition shared?

Is there maybe something here about skill or expertise?
>   - Colleen Pridemore: merit still needs clarification.Â  skills and expertise need to be evaluated to be included within the definition, "merit". Does merit imply the weight or impact their input has had on the project?
> 
#### Context - Consent
> * Vanessa Cardui: Is there also something here about AI transparency: i.e. that Archives users should be made aware of when AI is being used e.gÂ  as part of a search tool they are using, or to tag or catalogue material they are looking at? It's not exactly "consent" if there is not an alternative - but maybe there will be? (Resolved by Vanessa Cardui)
>   - Vanessa Cardui: I'd also like to include something on what I would call clarity or honesty or non-deceptiveness - we will not use AI that pretends to be human or to have emotions, or that tries to deceive humans into believing they are ineracting with a human or human-like entity, or arrogatesÂ  human functions to itself.

I dunno what people think about this - but it's one of the things I loathe about ChatGPT - it's always pretending to be human. If I ran the world, lol, AI chat bots would be banned even from saying "I feel", and they would definitely be banned from saying "I understand your feelings" or "I will strive to improve ". It's deceptive, and it gives people a mistaken impression of what AI tools actually are.
>   - Colleen Pridemore: I concurÂ completely
> 
