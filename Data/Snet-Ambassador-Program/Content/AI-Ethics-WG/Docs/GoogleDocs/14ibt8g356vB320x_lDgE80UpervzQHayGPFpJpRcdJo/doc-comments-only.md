#### Context - AI Avatar Chatbot
> * Nick Nayfack: A neuro symbolic LLM could do this via a SNET agent in terms of developer interaction. For the general public, a general purpose LLM will be assembled where folks can use whatever OSS LLM they like. See poe.com. With analytics and permission, users can decide what they want to share but by default their queries should be private.
> 
#### Context - beneficial
> * Nick Nayfack: Impact initiatives can vary in terms of being beneficial. As someone who has worked extensively in impact projects, successful impact occurs when financial or social interactions can be tracked and traced to measurable outcomes. For example, $1M of donations has lit up 10,000 homes for 5 hours/day in Nigeria and now 10% more of the population is able to complete college education from home. For AGI, this kind of impact is a bit tricky. What would the outcomes be? Compute is 10% more efficient than centralized data centers and has delivered access to 2M people in developing countries to bring 500,000 new jobs to regional non urban areas? Is this beneficial AGI?
> 
#### Context - governance
> * Nick Nayfack: This is a better place to start but, we have to be careful. Governance is also being weaponized to shut out everyone except major tech giants. We will be enumerating ourselves for SEC scrutiny if we aren't careful as AGIX/ASI will be examined as a security. We have to be very careful how we handle this. Very powerful companies are looking to secure their investments made on Nvidia chips (now including us) and their expensive LLMs. https://www.insideprivacy.com/artificial-intelligence/california-legislature-advances-several-ai-related-bills/#:~:text=Legislation%20Regulating%20AI%20Developers&text=A%20noncompliant%20system%20would%20incur,watermarks%20in%20AI%2Dgenerated%20content.
> 
#### Context - identify verification
> * Nick Nayfack: People will be reluctant to do this in web3. They will want to protect their privacy. Trust systems can help here potentially.
> 
#### Context - Donate/allocate resources
> * Nick Nayfack: We will likely need web3 incentives that are more monetary to spark self governance. Business best practices are often a forum where many of these issues come to surface in enterprise environments.
> 
#### Context - what do they value, what do they want in their future
> * Nick Nayfack: This could be a commons approach to governance practices. It feels like being prescriptive and aggregating inputs globally may or may not help people down the path of self governance. It may be useful to work with specific communities to create self governance frameworks vs. attempting to listen to, aggregate and apply AI ethics as a whole globally.
> 
#### Context - betterment of humanity
> * Nick Nayfack: Betterment for some can be detrimental to others. For example, the more compute that is used, the more energy is consumed and the more potential impact for climate change materially exists and is traceable per data center. The question becomes how do we address these fundamental ethical concerns prior to collecting ethical feedback? Ethics feels like a slippery slope to stand on. It feels like this should be reflected in governance. AI guardrails are also subject to each business and community. Safety is also community specific.
> 
#### Context - meaningful conversations
> * Nick Nayfack: How will we define meaningful?
> 
#### Context - voting weights (identity verification and positive and constructive actions and behavior, etc).
> * Nick Nayfack: Voting for what kinds of initiatives? Who is going to raise them? Where and how will they get resourced or actioned?
> 
#### Context - participation can enable humanity
> * Nick Nayfack: Qualified participation can enable humanity. The majority of people have little expertise on what AGI is, and it feels like more effort could be made to help educate people vs. collecting input based on the perception of technologies that are not yet functioning. Even internally, ask staff what AGI is and what functionality it actually provides. It may be interesting to start there.
> 
#### Context - ethics discussion forum,
> * Nick Nayfack: Is a discussion forum needed for ethics or is it more of a matter of best practices and concerns with AI safety?
> 
#### Context - Governance
> * Nick Nayfack: The idea of governance as a primary means of capturing this is good. Ethics are often embodied in values. Values can be challenging to translate into rules. Businesses and individuals often ignore or defy rules for the sake of achieving their own objectives. Best practices can sometimes mitigate this but it isn't clear or easy. Governance just leaves it in the hands of the community to define their practices. Their ethics will be implicitly reflected in their governance practices.
> 
#### Context - What areas of AI applications do you believe are most important at this moment?
> * Colleen Pridemore: Sorry, just got lost in reading and decided to answer! lol
>   - Vanessa Cardui: :-)
> 
#### Context - Computing
> * Vanessa Cardui: computing (no capital C) 
(sorry for the repeat comment, I accidentally resolved the first one, lol) (Resolved by Colleen Pridemore)
> 
#### Context - Computing
> * Vanessa Cardui: computing (no capital C) (Resolved by Vanessa Cardui)
> 
#### Context - FIAT
> * Vanessa Cardui: fiat
(no caps) - it's not an initialism - the word stems from Latin :-) (Resolved by Colleen Pridemore)
> 
#### Context - gather the collective intelligence of humanity
> * Vanessa Cardui: Heya - I feel like this paragraph should explicitly include a line about the "informed consent" element that Esther has mentioned in the comments. 

And also, maybe, it should somehow address the question of attribution? (or at the least, mentioning sources in general terms, like "from interviews conducted at (somewhere)"). It is kinda addressed further down with "Users are encouraged to identify themselves as a unique human being or identifiable individual. However, users can choose to remain anonymous." - but I feel like it might need to be here, in the "Goal" section, so the reader isn't left hanging?

I (like most of us, probably) am a bit uneasy with the ethics of this widely-used "crowdsourced wisdom" approach, cos it does often end up as kinda plundering ordinary people for their uncredited insights; and (just as always) ordinary working-class people being made historically/archivally invisible as individuals, in service of some "greater" initiative that wasn't shaped by them. So I feel like it needs to be stated immediately that this *isn't* what we're doing.

(and I'd need to have a real think about how I reckon something like this could be worded!)
>   - Colleen Pridemore: If you look at the definition of data computing in Wikipedia, it actually comes out as a function  (interestingly enough) https://simple.wikipedia.org/wiki/Data_(computing)  Which means all data: ie...'Data is a sequence of numbers, words, or other symbols' which when explained, becomes information.

I think this fits with the questions  abovementioned, right?
>   - Colleen Pridemore: In addition, I agree with your "informed consent" phrase you stated earlier
> 
#### Context - The creation of an educational video game for kids and adults to discover information about AI Ethics and help to alleviate fears, misconceptions or biases about AI
> * Colleen Pridemore: I will be presenting a pitch to R&D Group on 06/05/2024 for such a video game.  Want to make sure to be aligning with Decentralization practices.  Advice welcome
> 
#### Context - system will gather the collective intelligence of humanity and synthesize it into a knowledge base which serves as a crowdsourced resource of human wisdom and priorities, and stimulates reflection and action into long-range goals for us as a species.
> * Colleen Pridemore: how will it gather this information? I assume it is currently gathering.  Correct?  If so this is not white-hat ethical hacking.  It is BLACK hat pure hacking.
>   - Esther Galfalvi: Not sure what this comment means? We are hardly collecting any data yet, but all data that is being collected is currently being done by interviewers, not yet by AI, and only using informed consent forms. People know that the data will be processed by AI tools and is anonymised.
>   - Esther Galfalvi: I don’t believe that SingularityNET is collecting for this project yet at all,as we are just kicking off
> 
#### Context - Participants who contribute by data, computing, or financial means will be given some agency in how these contributions can or cannot be used.
> * Colleen Pridemore: Aren't there any other contributing factors? Such as contributing to the factors of this document for example?
>   - Vanessa Cardui: I kinda feel like this kind of work falls under the umbrella of "contributing data"? But actually, maybe not - maybe we need an additional one, something like "contribute by organising/planning/work/thinking??"
>   - Colleen Pridemore: I agree. I think "contributing data" can cover a host of actions, right?
> 
